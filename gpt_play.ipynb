{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3bc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import config as c\n",
    "from utils import WADataValidator\n",
    "import numpy as np1\n",
    "from random import randint\n",
    "# basically a utils file but including pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66e0774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded vocab\n"
     ]
    }
   ],
   "source": [
    "dv = WADataValidator(mode=\"train\")\n",
    "train_data = dv.train_data\n",
    "val_data = dv.val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5183b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2841284 315699\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a04c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33, 82, 71, 86, 72, 77,  1, 51, 84, 81])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4e6f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 82, 71, 86, 72, 77, 1, 51, 84, 81]\n",
      "Ashwin Sur\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "print(dv.encode(train_data[:n]))\n",
    "print(dv.decode(dv.encode(train_data[:n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d82cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = torch.tensor(dv.encode(train_data), dtype=torch.long), torch.tensor(dv.encode(val_data), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee5d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# things to keep in mind when implementing:\n",
    "# 1. sampling of training data must be random. that means your qna pair must be done out of no-where\n",
    "# 2. make sure successive texts are combined into one with some separator, probably a '.'\n",
    "# 3. qna pair is always going to be text at i'th position and i+1'th position within a certain 'conversation'\n",
    "# 4. a 'conversation' can be defined as texts within quick time frames. anything more than (say) 30mins is a different conversation.\n",
    "# 5. qna pair must be taken from the same conversation. maybe [(1,2), (3,4) ... ] or [(1,2), (2,3) ...] -> more thought needs to be put here. personally a fan of [(1,2), (2,3)]\n",
    "# 6. maybe have a start and end token with something like < >\n",
    "# 7. do some simple statistics on the messages to come up with appropriate block_size, conversation_length etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe85412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "block_size, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0edf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.encode(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d813077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33, 82, 71, 86, 72, 77,  1, 51, 84])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna = train_data[:block_size+1]\n",
    "qna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fef0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "for i in range(0, len(qna)-1):\n",
    "    x.append(qna[:i+1])\n",
    "    y.append(qna[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5de805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([33]),\n",
       "  tensor([33, 82]),\n",
       "  tensor([33, 82, 71]),\n",
       "  tensor([33, 82, 71, 86]),\n",
       "  tensor([33, 82, 71, 86, 72]),\n",
       "  tensor([33, 82, 71, 86, 72, 77]),\n",
       "  tensor([33, 82, 71, 86, 72, 77,  1]),\n",
       "  tensor([33, 82, 71, 86, 72, 77,  1, 51])],\n",
       " [tensor(82),\n",
       "  tensor(71),\n",
       "  tensor(86),\n",
       "  tensor(72),\n",
       "  tensor(77),\n",
       "  tensor(1),\n",
       "  tensor(51),\n",
       "  tensor(84)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfab488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(block_size = 8, batch_size = 4):\n",
    "    x, y = [], []\n",
    "    for _ in range(batch_size):\n",
    "        rand_pos = randint(0, len(train_data) - block_size)\n",
    "        x.append(train_data[rand_pos: rand_pos + block_size])\n",
    "        y.append(train_data[rand_pos + 1 : rand_pos + block_size + 1])\n",
    "    \n",
    "    x, y = torch.stack(x), torch.stack(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6555e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e7b7e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8]) torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[75, 78, 86,  1, 65, 84, 67, 70],\n",
       "         [74,  0, 19, 16,  1, 66, 64, 84],\n",
       "         [33, 67, 72, 83, 88, 64,  1, 46],\n",
       "         [67, 72, 83, 71, 88, 64,  1, 46]]),\n",
       " tensor([[78, 86,  1, 65, 84, 67, 70, 68],\n",
       "         [ 0, 19, 16,  1, 66, 64, 84, 82],\n",
       "         [67, 72, 83, 88, 64,  1, 46, 84],\n",
       "         [72, 83, 71, 88, 64,  1, 46, 64]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape, y.shape)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc91a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22fb753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n !\"#$%&\\'()*+,./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_abcdefghijklmnopqrstuvwxyz{|}~',\n",
       " 94)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = dv.vocab\n",
    "vocab, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5ea379d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dims = len(vocab)\n",
    "\n",
    "class BLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dims)\n",
    "        self.l = nn.Linear(embedding_dims, vocab_size)\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.l(x)\n",
    "        \n",
    "        if y is not None:\n",
    "            b, t, c = x.shape\n",
    "            x = x.view(b*t, c)\n",
    "            y = y.view(b*t)\n",
    "            loss = F.cross_entropy(x, y)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return x, loss\n",
    "\n",
    "    def generate(self, start_token = \" \", max_tokens=100):\n",
    "        with torch.no_grad():\n",
    "            token = torch.tensor(dv.encode(start_token), dtype=torch.long).view(1,-1)\n",
    "    #         print(token)\n",
    "            for _ in range(max_tokens-1):\n",
    "                ops, _ = self(token)\n",
    "                ops = ops[:, -1, :]\n",
    "                ops = F.softmax(ops, dim =1)\n",
    "                most_likely_char = torch.multinomial(ops, num_samples = 1)\n",
    "                token = torch.cat((token, most_likely_char), dim = 1)\n",
    "    #             print(token.shape)\n",
    "        return token\n",
    "    \n",
    "    def decode_tensor(self, generated_tensor):\n",
    "        return dv.decode(generated_tensor.cpu().detach().numpy().flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d7a6f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm = BLM()\n",
    "ops, loss = blm(x, y)\n",
    "# ops = blm.generate(\"something\")\n",
    "# print(ops, ops.shape)\n",
    "# print(ops.shape, loss)\n",
    "# print(blm.decode_tensor(ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa731373",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(blm.parameters(), lr = 3e-2)\n",
    "loss_fn =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8ecb48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.159623146057129\n",
      "2.515923261642456\n",
      "2.3146438598632812\n",
      "2.656872034072876\n",
      "2.635855197906494\n",
      "2.371776580810547\n",
      "2.4338738918304443\n",
      "2.5691001415252686\n",
      "2.2669153213500977\n",
      "3.009739398956299\n"
     ]
    }
   ],
   "source": [
    "for o in range(100000):\n",
    "    x, y = get_batch()\n",
    "    opt.zero_grad()\n",
    "    preds, loss = blm(x,y)\n",
    "#     loss = loss_fn(preds, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if o%10000 == 0: \n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "888fef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nutakkioplesscthmayaldiotyo jy limyoum n: itishers Ne Sut my\n",
      "Ad ad\n",
      "As\n",
      "So Chi: p\n",
      "LEm mourshu nera my\n",
      "As: ratothk: ape ware Ok: nkksthureoplt to mupi: @91302 a ?\n",
      "Lagyay wano herme tie rth: w twhis, k: watith pe agas ceyantwhk: abyo\n",
      "Ch: trexxpevat Nacayotlelond\n",
      "Pra mac hadrotrajyand>\n",
      "Adahitsusureyoma ndit Che jyer windithes owiveayshesthk: r\n",
      "Chw chodanchsoum ior\n",
      "Asarouply\n",
      "As the stca t\n",
      "Adind Brire thiguf v\n"
     ]
    }
   ],
   "source": [
    "ops = blm.generate(\"aaaaa\", max_tokens=400)\n",
    "# print(ops, ops.shape)\n",
    "# print(ops.shape, loss)\n",
    "print(blm.decode_tensor(ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05f6cda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[68,  1, 65, 78, 83, 83, 78, 76],\n",
       "         [14, 14,  1, 52, 71, 68, 88,  8],\n",
       "         [ 0, 35, 71, 64, 67, 64, 70, 64],\n",
       "         [71, 68,  1, 74, 68, 88,  1, 83]]),\n",
       " tensor([[ 1, 65, 78, 83, 83, 78, 76,  1],\n",
       "         [14,  1, 52, 71, 68, 88,  8, 81],\n",
       "         [35, 71, 64, 67, 64, 70, 64, 26],\n",
       "         [68,  1, 74, 68, 88,  1, 83, 78]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding layer: \n",
    "# MUST have vocab size number of rows. each having how many ever tensors -> w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0949a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b, t, c = 4, 8, 2\n",
    "# x = torch.randn(b,t,c)\n",
    "# xbow = torch.zeros(b,t,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "beeee62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1012,  0.3757],\n",
       "         [ 0.4441, -0.2062],\n",
       "         [ 1.0212, -0.3191],\n",
       "         [-0.2272,  1.3350],\n",
       "         [-0.4887, -0.4338],\n",
       "         [ 0.6428,  0.7826],\n",
       "         [-0.1964, -0.7348],\n",
       "         [-1.8919,  1.6051]],\n",
       "\n",
       "        [[-0.4052,  0.2195],\n",
       "         [ 0.1336,  0.0912],\n",
       "         [ 0.3155,  1.0410],\n",
       "         [ 0.7862,  0.2359],\n",
       "         [-1.6690,  0.8855],\n",
       "         [-1.3307,  2.0962],\n",
       "         [ 2.2630, -0.5606],\n",
       "         [ 0.2355, -0.4915]],\n",
       "\n",
       "        [[ 0.1991,  0.6489],\n",
       "         [ 0.3494,  0.1715],\n",
       "         [-0.0593,  1.8290],\n",
       "         [-2.1390,  1.4783],\n",
       "         [-0.4608, -0.9952],\n",
       "         [-0.1357, -0.9198],\n",
       "         [ 2.1055,  1.8290],\n",
       "         [ 1.6549,  2.0575]],\n",
       "\n",
       "        [[ 0.5459,  0.8105],\n",
       "         [-1.4135,  0.8328],\n",
       "         [ 0.9272, -1.1384],\n",
       "         [-0.7375, -1.7727],\n",
       "         [-0.0347, -1.5288],\n",
       "         [ 2.9100,  0.3882],\n",
       "         [-0.1150,  0.5159],\n",
       "         [ 0.4445, -0.0747]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c633a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _b in range(b):\n",
    "    for _t in range(t):\n",
    "        xbow[_b, _t] = x[_b, :_t+1, :].mean(dim = 0)\n",
    "#         print(x[_b, : _t+1, :], x[_b, :_t+1].mean())\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "dd6a3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, t, c = 4, 8, 12\n",
    "x = torch.randn(b,t,c)\n",
    "head_size = 16\n",
    "# key = nn.Linear(c, head_size)\n",
    "# query = nn.Linear(c, head_size)\n",
    "# value = nn.Linear(c, head_size)\n",
    "\n",
    "# k = key(x)\n",
    "# q = query(x)\n",
    "# wei = q @ k.transpose(-2, -1)\n",
    "\n",
    "# tril = torch.tril(torch.ones(t, t))\n",
    "# wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "# wei = F.softmax(wei, dim=-1)\n",
    "# out = wei @ x \n",
    "# out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "30f9b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size=16):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.key = nn.Linear(c, head_size)\n",
    "        self.query = nn.Linear(c, head_size)\n",
    "        self.value = nn.Linear(c, head_size)\n",
    "        self.tril = torch.tril(torch.ones(t, t))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        _b, _t, _c = x.shape\n",
    "        wei = (self.query(x) @ self.key(x).transpose(1, 2)) * (self.head_size**-0.5)\n",
    "#         print(\"init q.kT => \", wei[0], wei[0].shape)\n",
    "#         print()\n",
    "        wei = wei.masked_fill(self.tril == 0, float(\"-inf\"))\n",
    "#         print(\"after masked fill => \", wei[0], wei[0].shape)\n",
    "#         print()\n",
    "        wei = F.softmax(wei, dim = 2)\n",
    "#         print(\"after softmax => \", wei[0], wei[0].shape)\n",
    "#         print()\n",
    "        v = self.value(x)\n",
    "#         print(wei.shape, v.shape)\n",
    "        wei = wei @ v\n",
    "    \n",
    "        return wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "583ff3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Head(head_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4d605c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(b, t, c)\n",
    "o = h(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "857462fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[-0.6339, -0.0258,  1.4931, -0.8165, -0.1141,  0.4604, -0.7192,  0.2125,\n",
       "          -0.1326,  0.3182,  0.0272,  0.8803, -1.1237,  0.3702, -0.5943,  0.4128],\n",
       "         [ 0.0025, -0.0062,  0.8610, -0.4212, -0.3691,  0.6221, -1.3776,  0.0227,\n",
       "           0.0528,  0.3995, -0.1075,  0.2744, -0.6473,  0.1693, -0.2753,  0.1278],\n",
       "         [-0.2912, -0.0385,  0.4004, -0.1647, -0.2049,  0.6406, -1.1118,  0.0494,\n",
       "           0.1449,  0.3221, -0.2945, -0.1351, -0.3599,  0.2600, -0.4305, -0.2352],\n",
       "         [-0.7080, -0.0290,  0.9115, -0.4195, -0.1628,  0.4270, -0.3929,  0.0999,\n",
       "          -0.0776,  0.4068,  0.0087,  0.2633, -0.6063,  0.2209, -0.5197,  0.0628],\n",
       "         [-0.5701, -0.0876,  0.6018, -0.1959,  0.0996,  0.4171, -0.2121, -0.0321,\n",
       "          -0.0836,  0.0934,  0.0426,  0.1303, -0.3935,  0.2113, -0.4089,  0.0461],\n",
       "         [-0.7577, -0.1411,  0.4130, -0.1285,  0.1605,  0.4874, -0.2053, -0.0198,\n",
       "           0.0730,  0.1618, -0.1182, -0.0589, -0.3654,  0.5054, -0.6141, -0.0604],\n",
       "         [-0.3854, -0.2187,  0.4926, -0.1668,  0.0094,  0.3243, -0.1270, -0.1789,\n",
       "           0.0286,  0.3062,  0.0900, -0.0539, -0.3454,  0.3841, -0.4184,  0.1762],\n",
       "         [-0.2279, -0.1225,  0.6124, -0.1642, -0.1289,  0.4154, -0.4296, -0.2292,\n",
       "          -0.0705,  0.3289,  0.1419,  0.1010, -0.4002,  0.2359, -0.2526,  0.2658]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape, o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63355b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "22a8af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc3236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74febf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
